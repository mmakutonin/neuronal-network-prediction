{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_number = 10\n",
    "data_dir = '../data/'\n",
    "component_data_dir = data_dir + 'pca_models_pickled/'\n",
    "raw_data_dir = data_dir + 'data_raw_pickled/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_list():\n",
    "    return list(\n",
    "        map(\n",
    "            lambda path: path.split('_mat_dict')[0],\n",
    "            filter(\n",
    "                lambda path: '_mat_dict.pickle' in path if True else False,\n",
    "                os.listdir(path = raw_data_dir)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subject):\n",
    "    with open(component_data_dir + subject + '_PCA_model_num_comp_' + str(component_number) + '_transformed.pickle', \"rb\") as input_file:\n",
    "        model = pickle.load(input_file)\n",
    "    with open(raw_data_dir + subject + '_mat_dict.pickle', \"rb\") as input_file:\n",
    "        stimulus = pickle.load(input_file)['stim_full']\n",
    "    return model, stimulus, np.unique(stimulus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_df(timeseries, stimulus):\n",
    "    df = pd.DataFrame(timeseries)\n",
    "    df['stimulus'] = np.resize(stimulus, (stimulus.size, 1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, stimulus_values):\n",
    "    return_dict = {}\n",
    "    for stimulus in stimulus_values:\n",
    "        stim_data = df.loc[df['stimulus'] == stimulus]\n",
    "        del stim_data['stimulus']\n",
    "        return_dict[stimulus] = stim_data.to_numpy()\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_data(subject, stimulus, data):\n",
    "    with open(component_data_dir + subject + '_stim_period_' + stimulus + '_PCA_model_num_comp_' + str(component_number) + '_transformed.pickle', 'wb') as pickle_file:\n",
    "        pickle.dump(data, pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved key  0  in  subject_10\n",
      "Saved key  1  in  subject_10\n",
      "Saved key  2  in  subject_10\n",
      "Saved key  3  in  subject_10\n",
      "Saved key  4  in  subject_10\n",
      "Saved key  9  in  subject_10\n",
      "Saved key  10  in  subject_10\n",
      "Saved key  11  in  subject_10\n",
      "Saved key  12  in  subject_10\n",
      "Saved key  13  in  subject_10\n",
      "Saved key  14  in  subject_10\n",
      "Saved key  15  in  subject_10\n",
      "Saved key  16  in  subject_10\n",
      "Saved key  21  in  subject_10\n",
      "Saved key  22  in  subject_10\n",
      "Saved key  23  in  subject_10\n",
      "Saved key  0  in  subject_12\n",
      "Saved key  1  in  subject_12\n",
      "Saved key  2  in  subject_12\n",
      "Saved key  3  in  subject_12\n",
      "Saved key  4  in  subject_12\n",
      "Saved key  9  in  subject_12\n",
      "Saved key  10  in  subject_12\n",
      "Saved key  11  in  subject_12\n",
      "Saved key  12  in  subject_12\n",
      "Saved key  14  in  subject_12\n",
      "Saved key  15  in  subject_12\n",
      "Saved key  0  in  subject_13\n",
      "Saved key  1  in  subject_13\n",
      "Saved key  2  in  subject_13\n",
      "Saved key  3  in  subject_13\n",
      "Saved key  4  in  subject_13\n",
      "Saved key  9  in  subject_13\n",
      "Saved key  10  in  subject_13\n",
      "Saved key  11  in  subject_13\n",
      "Saved key  12  in  subject_13\n",
      "Saved key  14  in  subject_13\n",
      "Saved key  15  in  subject_13\n",
      "Saved key  0  in  subject_14\n",
      "Saved key  1  in  subject_14\n",
      "Saved key  2  in  subject_14\n",
      "Saved key  3  in  subject_14\n",
      "Saved key  4  in  subject_14\n",
      "Saved key  9  in  subject_14\n",
      "Saved key  10  in  subject_14\n",
      "Saved key  11  in  subject_14\n",
      "Saved key  12  in  subject_14\n",
      "Saved key  14  in  subject_14\n",
      "Saved key  15  in  subject_14\n",
      "Saved key  0  in  subject_15\n",
      "Saved key  1  in  subject_15\n",
      "Saved key  2  in  subject_15\n",
      "Saved key  3  in  subject_15\n",
      "Saved key  4  in  subject_15\n",
      "Saved key  9  in  subject_15\n",
      "Saved key  10  in  subject_15\n",
      "Saved key  11  in  subject_15\n",
      "Saved key  12  in  subject_15\n",
      "Saved key  14  in  subject_15\n",
      "Saved key  15  in  subject_15\n",
      "Saved key  1  in  subject_16\n",
      "Saved key  2  in  subject_16\n",
      "Saved key  3  in  subject_16\n",
      "Saved key  4  in  subject_16\n",
      "Saved key  9  in  subject_16\n",
      "Saved key  10  in  subject_16\n",
      "Saved key  11  in  subject_16\n",
      "Saved key  12  in  subject_16\n",
      "Saved key  0  in  subject_17\n",
      "Saved key  1  in  subject_17\n",
      "Saved key  2  in  subject_17\n",
      "Saved key  3  in  subject_17\n",
      "Saved key  4  in  subject_17\n",
      "Saved key  9  in  subject_17\n",
      "Saved key  10  in  subject_17\n",
      "Saved key  11  in  subject_17\n",
      "Saved key  12  in  subject_17\n",
      "Saved key  14  in  subject_17\n",
      "Saved key  15  in  subject_17\n",
      "Saved key  0  in  subject_1\n",
      "Saved key  1  in  subject_1\n",
      "Saved key  2  in  subject_1\n",
      "Saved key  3  in  subject_1\n",
      "Saved key  0  in  subject_2\n",
      "Saved key  1  in  subject_2\n",
      "Saved key  2  in  subject_2\n",
      "Saved key  3  in  subject_2\n",
      "Saved key  0  in  subject_3\n",
      "Saved key  1  in  subject_3\n",
      "Saved key  2  in  subject_3\n",
      "Saved key  3  in  subject_3\n",
      "Saved key  0  in  subject_4\n",
      "Saved key  1  in  subject_4\n",
      "Saved key  2  in  subject_4\n",
      "Saved key  3  in  subject_4\n",
      "Saved key  0  in  subject_5\n",
      "Saved key  1  in  subject_5\n",
      "Saved key  2  in  subject_5\n",
      "Saved key  3  in  subject_5\n",
      "Saved key  1  in  subject_6\n",
      "Saved key  2  in  subject_6\n",
      "Saved key  3  in  subject_6\n",
      "Saved key  1  in  subject_7\n",
      "Saved key  2  in  subject_7\n",
      "Saved key  3  in  subject_7\n"
     ]
    }
   ],
   "source": [
    "for subject in load_subject_list():\n",
    "    timeseries, stimulus, stimulus_values = load_data(subject)\n",
    "    df_full = create_data_df(timeseries, stimulus)\n",
    "    split_data_dict = split_data(df_full, stimulus_values)\n",
    "    for key, data in split_data_dict.items():\n",
    "        save_split_data(subject, str(key), data)\n",
    "        print('Saved key ', key, ' in ', subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
